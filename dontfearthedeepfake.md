## Don't Fear the Deepfake

Let's do a little tabletop exercise. Imagine this scenario: 

**_You're a founder and CEO of a fast-growing company--something in fintech, say, or medtech, or edtech, or no-prefix tech; it doesn't really matter. Late on a Friday, you discover a monumental oversight, one that will have devastating effects on your bottom line if uncorrected, so thank god you discovered it just in time. A transfer of funds that was supposed to lock down a highly valuable client--one that you've staked a lot on--never went through, and you're about to lose 35% of next quarter's projected earnings._**

**_You call up the CFO (thanking god again that they're available for a Zoom) and explain the situation. You both agree  that there's no time to lose. Somebody has to send that wire, and it's gotta be somebody you can trust to keep it on the DL; you can't afford to let word of this get back to investors._**

**_You shoot an email to a very trusted employee asking if they can hop into a Zoom call right now, apologizing for pulling them into something right before the weekend, but letting them know it's urgent and they're the only one you can trust. They get into the call, you and your CFO explain what's going on, how you're on the precipice of disaster, how if this transfer doesn't go through layoffs are a near certainty, or worse._**

**_You explain that all you need them to do is send the funds today, before the weekend, and that this call can fill in for the formal approval process. You'll debrief on Monday to figure out where this all went wrong._**

In this situation, what would you want your employee to do?

You'd want them to tell you to fuck off.  Or maybe just hang up and don't say anything at all. You'd want them to ignore your pleas, your cajoling, your explanation of the very real situation you're all facing. You'd want them to ignore the threats to the company, the threats to their job, the threats to their coworkers' jobs. 

If they didn't, if they took you seriously even for a second, that means you have failed. As a manager, as a leader, and as an executive.

I'm a security researcher. I research deepfakes, and I've even made a few myself. They are tremendously easy to make; on my three-year-old gaming laptop I can make a decent-looking deepfake overnight, and with cloud computing I can make one in an hour for cheap. Hell, I could make four with the same amount of money it takes to buy [a pound of tootsie rolls.](https://www.amazon.com/Individually-Chocolate-Hampton-Popcorn-Company/dp/B0CHWN53YL?crid=152NMI39CUHMA&dib=eyJ2IjoiMSJ9.xWRETUy6Wdu-vnO8tOKQPsKQCkefZg5tDr91Navd4NpJqAZwn2bCp8Eu1E_wA9NIlR0hZWNmXt7seHKod6OUJHQUEdSWq0hu81fAHIezsxA1ebGvAZIhEqV4-QOrkXR3ZZ8BKlXstg8RAAA1HmmPIzoTVye94SmmKUc0x_nyIUQZSaQyNUZk-hiw7Q3vpF5pnl2Nu4SxkaVA8LBCQj3HJ8NNYuWGfUpsZe89e-AXAGOubwe8rHLlGz6oRtY3egKxbbrvvNhlRGSIRJmPLnp2jF_s8_KHzDxeidL7tmApSis.sx5HxdgWi1MTkeD6utZZZRgkrz7KfKHtqgriZhabIz0&dib_tag=se&sprefix=tootsie%2Br%2Caps%2C752)  Real-time deepfakes (that is, deepfakes where the faker can respond and react to the victim without dropping the disguise) are [very much improving](https://www.semanticscholar.org/reader/ded29eb745392bd7ec16285f7ab4bcc33892d436) while deepfake detection is [always half a step behind](https://vsrp.co.uk/wp-content/uploads/4-IJCI-Vol.-3-No.-8-August-2024-paper3-Ms.-Weeam.pdf).

One thing is very clear: it is no longer possible to place the same kind of trust in any kind of digital communication that we did even five years ago. 

Now, this is awful in a lot of ways, as misinformation and exploitative material explodes across the [AI-stuffed internet](https://www.semanticscholar.org/reader/8eb6b0dc02f1a6ec06fe024071f6ddc1842a49bb), and the last natural defenses against complete [anti-truth hysteria begin to erode](https://www.semanticscholar.org/reader/ceccf5077ff16baf7df97abe9ba48e0e1ec267a0), slowly but unstoppably leading our society towards that one scene in Event Horizon where the guy sticks forks in his eyes (google that one, I'm not linking it). 

But there is good news: actual fraud using deepfakes isn't really anything to be worried about. 

By that I don't mean that deepfake fraud doesn't happen, it does. I mean that you shouldn't really be particularly worried about it. The thing about fraud is that it doesn't really matter how "believable" a particular lie is; that's why fraudsters use [psychological tricks to deactivate the part of our brain that does smell tests](https://consumer.ftc.gov/articles/how-avoid-scam). Take the exercise above: compliance wonks among you spotted these tricks right away, and once you see them, they're impossible to ignore. The last-minute timing, the urgency, the seriousness, the hand waving of procedure, the charged emotions. That kind of scenario is baby's first spoof, but it's common because it works. 

People get flustered in urgent situations, when people in power are panicking at them, when they are both flattered (you're the most trustworthy employee) and cowed (if you fail, everyone is fucked). This is the strategy used by [deepfakers in Hong Kong who made off with $25 million](https://edition.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html), but it's happened too countless times over email, text, phone, faxes, telegrams, and carrier pigeons. In truth, the technology involved is sort of irrelevant. The strength of this kind of fraud doesn't come from its verisimilitude, it comes from its vibes. 

The best defenses against any kind of fraud, whether deepfake-enabled or not, fit into the broad categories of [operational](https://www.journalofaccountancy.com/issues/2023/aug/preventing-fraud-with-internal-controls-a-refresher.html) and [cultural](https://www.shrm.org/topics-tools/news/risk-management/fight-fraud-employee-awareness). 

Operationally, you should have procedures. Policies. Protocols. Whatever P word you wanna call it, make sure you have some written words that clearly and completely lay out the steps that need to be taken to protect high-value assets or high-risk initiatives--and medium- and low-value for that matter. These controls do the bulk of the prevention, detection, and remediation for you, so you don't have to worry when an incident does, inevitably, occur. Your industry has standards. Learn them, hew to them, adapt to them. Flexibility is a virtue unless what you're bending is the rules.

Once you've got your standards standardized, make sure everybody knows that nobody is above those standards, and I mean nobody. Think about what your team would do if you yelled at them to break the rules. If they're afraid of you, a fraudster will exploit that fear. Think about what your team would do if you asked them to break the rules. If they're loyal to you, a fraudster will exploit that loyalty too. Trust is good between teammates but, when it comes to protecting your organization, trust canâ€™t replace regulations.

The ML boom is presenting us plenty of new problems, but not all of them need new solutions. Like with AI-enabled hacking or AI-assisted development, deepfake-enabled fraud is an old tangelo in a new peel, and it'll juice all the same. 
